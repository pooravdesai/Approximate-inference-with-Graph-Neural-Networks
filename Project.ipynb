{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "guCeu7HBdeNz",
    "outputId": "65907b49-e1b7-4cb5-c3f5-a4016fa32feb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install pgmpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AJFWSiv_8q-K"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G8wIy2Kv-vrq"
   },
   "outputs": [],
   "source": [
    "#creating 100 graphs with nodes of the given structure\n",
    "def graph_creation(nodes,graph_structure):\n",
    "  W_matrix=[]\n",
    "  b_matrix=[]\n",
    "  for index in range(200):\n",
    "    matrix=nx.to_numpy_array(graph_structure)\n",
    "    W=np.random.normal(0.,1.,(nodes,nodes))\n",
    "    W=(W+W.T)/2\n",
    "    W*=matrix\n",
    "    W_matrix.append(W)\n",
    "    b_matrix.append(np.random.normal(0.,0.25,nodes)) #random generation\n",
    "  return(W_matrix,b_matrix)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#creating the whole dataset for 5 nodes:\n",
    "import math\n",
    "\n",
    "def dataset(nodes):\n",
    "  W_star,b_star=graph_creation(nodes,nx.star_graph(nodes-1))\n",
    "  W_complete,b_complete=graph_creation(nodes,nx.complete_graph(nodes))\n",
    "  W_BP,b_BP=graph_creation(nodes,nx.complete_bipartite_graph(math.ceil(nodes/2),nodes-math.ceil(nodes/2)))\n",
    "  W_path,b_path=graph_creation(nodes,nx.path_graph(nodes))\n",
    "\n",
    "  W_wheel,b_wheel=graph_creation(nodes,nx.wheel_graph(nodes))\n",
    "  W_lollipop,b_lollipop=graph_creation(nodes,nx.lollipop_graph(math.ceil(nodes/2),nodes-math.ceil(nodes/2)))\n",
    "  W_cycle,b_cycle=graph_creation(nodes,nx.cycle_graph(nodes))\n",
    "\n",
    "  J=np.array(W_star+W_complete+W_BP+W_path+W_wheel+W_lollipop+W_cycle)\n",
    "  b=np.array(b_star+b_complete+b_BP+b_path+b_path+b_wheel+b_lollipop+b_cycle)\n",
    "  return (J,b)\n",
    "\n",
    "J5_1400,b5_1400=dataset(5)\n",
    "J10_1400,b10_1400=dataset(10)\n",
    "\n",
    "\n",
    "joblib.dump(J5_1400,'/content/drive/My Drive/PGM/Project/J5_1400')\n",
    "joblib.dump(J10_1400,'/content/drive/My Drive/PGM/Project/J10_1400')\n",
    "joblib.dump(b5_1400,'/content/drive/My Drive/PGM/Project/b5_1400')\n",
    "joblib.dump(b10_1400,'/content/drive/My Drive/PGM/Project/b10_1400')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tSncM3C1RkKZ"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "J5=joblib.load('/content/drive/My Drive/PGM/Project/J5_1400')\n",
    "J10=joblib.load('/content/drive/My Drive/PGM/Project/J10_1400')\n",
    "\n",
    "b5=joblib.load('/content/drive/My Drive/PGM/Project/b5_1400')\n",
    "b10=joblib.load('/content/drive/My Drive/PGM/Project/b10_1400')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vpvpCdw8Dw0S"
   },
   "outputs": [],
   "source": [
    "#Compute the marginals by enumeration exact inference\n",
    "def generate_marginals(J, b):\n",
    "  nodes = b.shape[1]\n",
    "  target = []\n",
    "  x_inputs = np.array(list(itertools.product(range(2), repeat=nodes)))\n",
    "  #print(x_inputs)\n",
    "  for J_i, b_i in zip(J, b):\n",
    "    # print(J_i.shape, b_i.shape)\n",
    "    target_i = []\n",
    "    b_i.shape = b_i.shape[0], 1\n",
    "    for x in x_inputs:\n",
    "      x.shape = x.shape[0], 1\n",
    "      prob_i = np.exp(b_i.T.dot(x) + x.T.dot(J_i).dot(x))\n",
    "      target_i.append(prob_i[0,0])\n",
    "    target_i = np.array(target_i)/np.sum(target_i)\n",
    "    target.append(target_i)\n",
    "  return np.array(target)\n",
    "\n",
    "# this generates the total joint probability distribution. [00,01,10,11] -> [prob(00), prob(01), ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PypbJLEgJ8sR"
   },
   "outputs": [],
   "source": [
    "target5 = generate_marginals(J5, b5)\n",
    "target10 = generate_marginals(J10, b10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VgkSmCwIY59g"
   },
   "outputs": [],
   "source": [
    "#calculating the marginals of each varible:\n",
    "def variable_marginals(target,nodes):\n",
    "  variable_marginal=[]\n",
    "  for index in range(len(target)):\n",
    "      marginal=[]\n",
    "      x_inputs = np.array(list(itertools.product(range(2), repeat=nodes)))\n",
    "      for var in range(nodes-1,-1,-1):\n",
    "        indices=[i for i, x in enumerate(x_inputs) if x[var] == 0]\n",
    "        temp=[sum(target[index][indices]),1-sum(target[index][indices])]\n",
    "        marginal.append(temp)\n",
    "      variable_marginal.append(np.array(marginal))\n",
    "  return variable_marginal\n",
    "\n",
    "true_marginal5=variable_marginals(target5,5)\n",
    "true_marginal10=variable_marginals(target10,10)\n",
    "#true_marginal15=variable_marginals(target15,15)\n",
    "#true_marginal20=variable_marginals(target20,20)\n",
    "\n",
    "# prob distribution of each variable. ex: prob(x1 = 0), prob(x1= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HrW97ZCHd9B3",
    "outputId": "4b392291-149a-4f69-d9e6-98a3356a9bcc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(true_marginal5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e9mJzGtC-rDe"
   },
   "outputs": [],
   "source": [
    "'''joblib.dump(true_marginal5,'/content/drive/My Drive/PGM/Project/true_marginal5_1400')\n",
    "joblib.dump(true_marginal10,'/content/drive/My Drive/PGM/Project/true_marginal10_1400')'''\n",
    "\n",
    "\n",
    "\n",
    "true_marginal5=joblib.load('/content/drive/My Drive/PGM/Project/true_marginal5_1400')\n",
    "true_marginal10=joblib.load('/content/drive/My Drive/PGM/Project/true_marginal10_1400')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TTFAkeEPVQMN"
   },
   "source": [
    "# Gated Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2PL_bWFC1v60"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dsIuC0y7WbWH"
   },
   "outputs": [],
   "source": [
    "path_to_pgm = \"/content/drive/My Drive/PGM Project\"\n",
    "path_to_data = os.path.join(path_to_pgm, \"Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phbSIaBEWj8y"
   },
   "outputs": [],
   "source": [
    "J5=joblib.load(os.path.join(path_to_data, \"J5\"))\n",
    "J10=joblib.load(os.path.join(path_to_data, \"J10\"))\n",
    "J15=joblib.load(os.path.join(path_to_data, \"J15\"))\n",
    "\n",
    "\n",
    "b5=joblib.load(os.path.join(path_to_data, \"b5\"))\n",
    "b10=joblib.load(os.path.join(path_to_data, \"b10\"))\n",
    "b15=joblib.load(os.path.join(path_to_data, \"b15\"))\n",
    "\n",
    "\n",
    "targets5 = joblib.load(os.path.join(path_to_data, \"true_marginal5\"))\n",
    "targets10 = joblib.load(os.path.join(path_to_data, \"true_marginal10\"))\n",
    "targets15 = joblib.load(os.path.join(path_to_data, \"true_marginal15\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "g7JNXiBEWk_O",
    "outputId": "d1abd884-a2b3-4b0b-cc2c-09943cc2ba56"
   },
   "outputs": [],
   "source": [
    "targets5 = np.array(targets5)\n",
    "targets10 = np.array(targets10)\n",
    "targets15 = np.array(targets15)\n",
    "print(targets5.shape, targets10.shape, targets15.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWfD8glyQk56"
   },
   "outputs": [],
   "source": [
    "class GatedGNN(nn.Module):\n",
    "  def __init__(self,\n",
    "               message_dim=5,\n",
    "               hidden_state_dim=5,\n",
    "               n_hidden_units_message=64,\n",
    "               n_hidden_units_readout=64,\n",
    "               n_timesteps=10\n",
    "               ):\n",
    "    super(GatedGNN, self).__init__()\n",
    "\n",
    "    self.message_dim = message_dim\n",
    "    self.hidden_state_dim = hidden_state_dim\n",
    "    self.n_hidden_units_message = n_hidden_units_message\n",
    "    self.n_hidden_units_readout = n_hidden_units_readout\n",
    "    self.n_timesteps = n_timesteps\n",
    "\n",
    "    # message passing MLP\n",
    "    self.messageFunction = nn.Sequential(\n",
    "        nn.Linear(2*hidden_state_dim+3, n_hidden_units_message),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(n_hidden_units_message, n_hidden_units_message),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(n_hidden_units_message, message_dim)\n",
    "        )\n",
    "    \n",
    "    # GRU unit that updates the hidden states\n",
    "    self.hiddenStateUpdateFunction = nn.GRUCell(message_dim, hidden_state_dim)\n",
    "\n",
    "    # Readout MLP\n",
    "    self.readoutFunction = nn.Sequential(\n",
    "        nn.Linear(hidden_state_dim, n_hidden_units_readout),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(n_hidden_units_readout, n_hidden_units_readout),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(n_hidden_units_readout, 2)\n",
    "        )\n",
    "    \n",
    "    self.initialize()\n",
    "  \n",
    "  def initialize(self):\n",
    "    for m in self.modules():\n",
    "      if isinstance(m, nn.Linear):\n",
    "        m.weight.data.normal_(0, 0.1)\n",
    "        m.bias.data.fill_(0)\n",
    "  \n",
    "  def forward(self, J, b):\n",
    "    '''\n",
    "      J: adjacency matrix tensor corresponding to a single graph. shape:(n,n)\n",
    "      b: singletons tensor corresponding to a single graph. shape:(n,)\n",
    "    '''\n",
    "    n_nodes = J.shape[0]\n",
    "    # messages = torch.zeros((n_nodes, self.message_dim))\n",
    "    messages_node_i_node_j = torch.zeros((n_nodes, n_nodes, self.message_dim))\n",
    "    hidden_states = torch.zeros((n_nodes, self.hidden_state_dim))\n",
    "\n",
    "    for _ in range(self.n_timesteps):\n",
    "      for node_i in range(n_nodes):\n",
    "        for node_j in range(n_nodes):\n",
    "          if J[node_i, node_j] != 0:\n",
    "            input_to_message_function = torch.unsqueeze(\n",
    "                torch.cat(\n",
    "                    (\n",
    "                        hidden_states[node_i], \n",
    "                        hidden_states[node_j], \n",
    "                        torch.tensor([J[node_i, node_j], b[node_i], b[node_j]])\n",
    "                    ),\n",
    "                    dim=0\n",
    "                ),\n",
    "                dim=0\n",
    "            )\n",
    "            message_from_node_i_to_node_j = self.messageFunction(input_to_message_function)\n",
    "            # messages[node_j] += message_from_node_i_to_node_j[0]\n",
    "            messages_node_i_node_j[node_i, node_j, :] = message_from_node_i_to_node_j[0]\n",
    "      messages = torch.sum(messages_node_i_node_j,dim=0)\n",
    "      hidden_states = self.hiddenStateUpdateFunction(messages, hidden_states)\n",
    "    \n",
    "    readout = self.readoutFunction(hidden_states)\n",
    "    marginals = nn.Softmax(dim=1)(readout)\n",
    "    # marginals = nn.Sigmoid()(readout)\n",
    "    return marginals\n",
    "  \n",
    "  def train(self, J, b, targets, optimizer, loss_function, n_epochs=10, batch_size=50):\n",
    "    '''\n",
    "      optimizer: example :- Adam(GatedGNNobj.parameters(), lr=learning_rate).\n",
    "      loss_function: example :- BinaryCrossEntropy() OR KLDivergenceLoss().\n",
    "      n_epochs: no. of epochs.\n",
    "      batch_size: no. of datapoints in a batch.\n",
    "    '''\n",
    "    # batch_loss_means = []\n",
    "    for epoch_i in range(n_epochs):\n",
    "      batch_losses = []\n",
    "      count = 1\n",
    "      batch_no = 0\n",
    "      for J_i, b_i, targets_i in zip(J, b, targets):\n",
    "        J_tensor = torch.from_numpy(J_i).float()\n",
    "        b_tensor = torch.from_numpy(b_i).float()\n",
    "        targets_tensor = torch.from_numpy(targets_i).float()\n",
    "\n",
    "        marginals = self(J_tensor, b_tensor)\n",
    "        loss_i = loss_function(marginals, targets_tensor)\n",
    "        batch_losses.append(loss_i)\n",
    "        \n",
    "        if count%batch_size == 0:\n",
    "          batch_no += 1\n",
    "          self.zero_grad()\n",
    "          \n",
    "          batch_loss_mean = torch.stack(batch_losses).mean()\n",
    "          batch_loss_mean.backward()\n",
    "          \n",
    "          optimizer.step()\n",
    "          \n",
    "          # batch_loss_means.append(batch_loss_mean.item())\n",
    "          print(\"epoch \"+str(epoch_i)+\", batch \"+str(batch_no)+\" loss: \", batch_loss_mean.item())\n",
    "          count = 0\n",
    "          batch_losses = []\n",
    "        \n",
    "        count += 1\n",
    "      if len(batch_losses) > 0:\n",
    "        batch_no += 1\n",
    "        self.zero_grad()\n",
    "        batch_loss_mean = torch.stack(batch_losses).mean()\n",
    "        batch_loss_mean.backward()\n",
    "        optimizer.step()\n",
    "        print(\"epoch \"+str(epoch_i)+\", batch \"+str(batch_no)+\" loss: \", batch_loss_mean.item())   \n",
    "  \n",
    "  def inference(self, J, b):\n",
    "    '''\n",
    "      J: adjacency matrices of graphs. shape: (N, nodes, nodes)\n",
    "      b: singletons of graphs. shape: (N, nodes)\n",
    "    '''\n",
    "    marginals = []\n",
    "    with torch.no_grad():\n",
    "      for J_i, b_i in zip(J, b):\n",
    "        J_tensor = torch.from_numpy(J_i).float()\n",
    "        b_tensor = torch.from_numpy(b_i).float()\n",
    "        marginals_i = self(J_tensor, b_tensor)\n",
    "        marginals.append(marginals_i.detach().numpy())\n",
    "    return np.array(marginals)\n",
    "  \n",
    "  def save_model(self, path):\n",
    "    '''\n",
    "      path: path to save the model.\n",
    "    '''\n",
    "    torch.save(self.state_dict(), path)\n",
    "\n",
    "\n",
    "\n",
    "def load_model(model, path):\n",
    "  '''\n",
    "    model: GatedGNN object in which the saved model has to be loaded.\n",
    "    path: path to the saved model.\n",
    "  '''\n",
    "  state_dict = torch.load(path, map_location=lambda storage,loc: storage)\n",
    "  model.load_state_dict(state_dict)\n",
    "\n",
    "class BinaryCrossEntropyLoss:\n",
    "  def __init__(self):\n",
    "    self.function = nn.BCELoss()\n",
    "  \n",
    "  def __call__(self, ypred, y):\n",
    "    return self.function(ypred, y)\n",
    "\n",
    "class KLDivergenceLoss:\n",
    "  def __init__(self):\n",
    "    self.function = nn.KLDivLoss()\n",
    "  \n",
    "  def __call__(self, ypred, y):\n",
    "    ypred_log = torch.log(ypred)\n",
    "    return self.function(ypred_log, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gbJD6G3tVn0C"
   },
   "outputs": [],
   "source": [
    "''' load model '''\n",
    "ggnn = GatedGNN()\n",
    "load_model(ggnn, os.path.join(path_to_pgm, \"models/ggnn_model_J5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "SOhPMcuAVfEs",
    "outputId": "571719d6-0c37-414a-9403-50007b637934",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "ypred = ggnn.inference(J5, b5)\n",
    "kldloss = KL_loss(ypred, targets5)\n",
    "# kldloss = KLDivergenceLoss()(torch.from_numpy(ypred).float(), torch.from_numpy(targets[-100:, :]).float())\n",
    "print(\"kld loss: \", kldloss, np.sum(kldloss))\n",
    "end_time = time.time()\n",
    "print(\"time taken: \", (end_time-start_time)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6huDwyi-1V8E"
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "####################MCMC###################################\n",
    "\n",
    "def samples(W,b,number_samples):\n",
    "        samples=[]\n",
    "        X = np.array([1 if np.random.rand() < .5 else -1 for i in range(len(b))])\n",
    "        #print(X.shape)\n",
    "        sample = [np.copy(X)]\n",
    "        for i in range(5000):\n",
    "            for j in range(len(b)):\n",
    "                t = W[j,:].dot(X)+b[j]\n",
    "                conditional_prob=1./(1.+np.exp(-t))\n",
    "                X[j] = +1 if np.random.rand() < conditional_prob else -1\n",
    "            sample.append(np.copy(X))\n",
    "        index=np.random.randint(0,5,number_samples)\n",
    "        sample=pd.DataFrame(sample)\n",
    "        samples.append(np.array(sample.iloc[index]))\n",
    "\n",
    "        return samples\n",
    "\n",
    "def MCMC(graph_samples):\n",
    "    result = []\n",
    "    for samples in graph_samples:\n",
    "        sample01 = np.where(samples > 0,0,1)\n",
    "        sample01 = np.array(sample01)\n",
    "        #print(sample01)\n",
    "        positive = sample01.mean(axis=0)\n",
    "        result.append(np.stack([1-positive, positive], axis=1))\n",
    "    return result\n",
    "\n",
    "\n",
    "def prediction(J,b):\n",
    "  predicted_MCMC=[]\n",
    "  for index in range(len(J)):\n",
    "    graph_samples=samples(J[index],b[index],number_samples=1000)\n",
    "    #print(graph_samples)\n",
    "    predicted_MCMC+=(MCMC(graph_samples))\n",
    "  return predicted_MCMC\n",
    "\n",
    "#calculation of time for different number of nodes with same number of graphs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DxFfvHpfEC6z"
   },
   "outputs": [],
   "source": [
    "#KL Loss for MCMC algorithm:\n",
    "def KL_loss(p, q):\n",
    "  result=0\n",
    "  for i in range(len(p)):\n",
    "    if q[i].all()!=0:\n",
    "\t    result+=((p[i] * np.log(p[i]/q[i])))\n",
    "    else:\n",
    "      result+=((p[i] * np.log(p[i]/0.001)))\n",
    "  #print(result)\n",
    "  return sum(result)/len(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S8sqB5e1Ru-9"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "startTime=time.time()\n",
    "predicted_MCMC5=prediction(J5,b5)\n",
    "endTime=time.time()\n",
    "print(\"The Time Required For 5 nodes graph is (in seconds)\",endTime-startTime)\n",
    "\n",
    "\n",
    "startTime=time.time()\n",
    "predicted_MCMC10=prediction(J10,b10)\n",
    "endTime=time.time()\n",
    "print(\"The Time Required For 10 nodes graph is (in seconds)\",endTime-startTime)\n",
    "\n",
    "\n",
    "\n",
    "startTime=time.time()\n",
    "predicted_MCMC15=prediction(J15,b15)\n",
    "endTime=time.time()\n",
    "print(\"The Time Required For 15 nodes graph is (in seconds)\",endTime-startTime)\n",
    "\n",
    "\n",
    "startTime=time.time()\n",
    "predicted_MCMC20=prediction(J20,b20)\n",
    "endTime=time.time()\n",
    "print(\"The Time Required For 20 nodes graph is (in seconds)\",endTime-startTime)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Loss for graphs with nodes 5 is \",sum(KL_loss(true_marginal5,predicted_MCMC5)))\n",
    "print(\"Loss for graphs with nodes 10 is \",sum(KL_loss(true_marginal10,predicted_MCMC10)))\n",
    "#print(\"Loss for graphs with nodes 15 is \",sum(KL_loss(true_marginal15,predicted_MCMC15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "81GQTURY1qqP",
    "outputId": "aa19319e-0f5b-475f-b333-6d3bfc4f66ab",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##############################BP########################\n",
    "### code is written only for star graph with nodes 5 else changes are made for marking the observations\n",
    "\n",
    "\n",
    "from pgmpy.models import FactorGraph\n",
    "from pgmpy.factors.discrete import DiscreteFactor\n",
    "from pgmpy.inference import BeliefPropagation\n",
    "def star_factor_graph(J,b):\n",
    "  prediction=' '\n",
    "  G = FactorGraph()\n",
    "  G.add_nodes_from(['x1', 'x2', 'x3','x4','x5'])\n",
    "  f1 = DiscreteFactor(['x1', 'x2'], [2, 2], np.exp(np.array([[0,0],[0,J[0][1]]])))\n",
    "  f2 = DiscreteFactor(['x1', 'x3'], [2, 2], np.exp(np.array([[0,0],[0,J[0][2]]])))\n",
    "  f3 = DiscreteFactor(['x1', 'x4'], [2, 2], np.exp(np.array([[0,0],[0,J[0][3]]])))\n",
    "  f4 = DiscreteFactor(['x1', 'x5'], [2, 2], np.exp(np.array([[0,0],[0,J[0][4]]])))\n",
    "  f5 = DiscreteFactor(['x1'], [2], np.exp(np.array([[0,b[0]]])))\n",
    "  f6 = DiscreteFactor(['x2'], [2], np.exp(np.array([[0,b[1]]])))\n",
    "  f7 = DiscreteFactor(['x3'], [2], np.exp(np.array([[0,b[2]]])))\n",
    "  f8 = DiscreteFactor(['x4'], [2], np.exp(np.array([[0,b[3]]])))\n",
    "  f9 = DiscreteFactor(['x5'], [2], np.exp(np.array([[0,b[4]]])))\n",
    "  G.add_factors(f1,f2,f3,f4,f5,f6,f7,f8,f9)\n",
    "  G.add_edges_from([('x1',f1),('x1',f2),('x1',f3),('x1',f4),(f1,'x2'),(f2,'x3'),(f3,'x4'),(f4,'x5'),(f5,'x1'),(f6,'x2'),(f7,'x3'),(f8,'x4'),(f9,'x5')])\n",
    "  k=BeliefPropagation(G)  \n",
    "  return k                      \n",
    " \n",
    "def predict(bp):\n",
    "  predict=[]\n",
    "  predict+=[str(bp.query(['x1']))[79:85],str(bp.query(['x1']))[123:129]]\n",
    "  predict+=[str(bp.query(['x2']))[79:85],str(bp.query(['x2']))[123:129]]\n",
    "  predict+=[str(bp.query(['x3']))[79:85],str(bp.query(['x3']))[123:129]]\n",
    "  predict+=[str(bp.query(['x4']))[79:85],str(bp.query(['x4']))[123:129]]\n",
    "  predict+=[str(bp.query(['x5']))[79:85],str(bp.query(['x5']))[123:129]]\n",
    "  return predict\n",
    "\n",
    "def prediction_values(J,b):\n",
    "  result=[]\n",
    "  for index in range(len(J)):\n",
    "    bp=star_factor_graph(J[index],b[index])\n",
    "    prediction=predict(bp)\n",
    "    prediction=[float(x) for x in prediction]\n",
    "    sum_var=sum(prediction[0:2])\n",
    "    for index in range(0,10,2):\n",
    "      prob=[i/sum_var for i in prediction]\n",
    "    split=[2,4,6,8]\n",
    "    prob=[prob[i : j] for i, j in zip([0] + split , split + [None])]  \n",
    "    result.append(np.array(prob))\n",
    "  return result\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "startTime=time.time()\n",
    "predicted_star5BP= prediction_values(J5[:50],b5[:50])\n",
    "endTime=time.time()\n",
    "print(\"The Time Required For 5 nodes star graph is (in seconds)\",endTime-startTime)  \n",
    "print(\"The KL Loss for 5 nodes star graph is \",sum(KL_loss(true_marginal5[:50],predicted_star5BP)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PGM_MCMC.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
